{"data":{"featured":{"edges":[{"node":{"frontmatter":{"title":"Segmentation for Tumor Detection","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABx0lEQVQoz22SS2/aYBBFbUN52GAnPGrAKsIkvEILwXwGDHZC7QCbrqIu+lJaqauq2676508FyCkEFrMYzeho5t4rSZJEXKVSiWq1SqFQwDTNXcmyzOFOXEb+glKhjKpqL2f/G0VRUBLKMySRSJyFtewWbiSYhiMmrkOn0yGVSp0CY0i/38eyrLOw7Ksso+WQ7B8Dy/fp+T7TucB8bZ4CC2UdMRyxCldsNhu63S7pdPoImElmcVYDzI997Np38j9nlIWOJClI8gEwLedpzX2aT7dEH5as1muCINi9s5Xi6OWrNg/Rey6bl2S9DGpJRZbk4wsriRpfpAGW80jra4+JcJlOp7iui2EYR8BkMomu68+9pmpkspm435PVRMSjtOYm9xc3XODNZiwWPvP5fOf6Sy2LxSLtTht3OKFeqR/O9sCiauPZn8n/GCP8IWLk4nneDhjrGLu/jVcURYT3If2nHs4nh4pZPjVlIG7p/m7yNnpHeBcSPUQ0Go2T665b14ThFhhQ/tXlavSNmrE8BaaTKW46fYbOkLEzxrbts9Gp1+sIIVje3zH2A0QxwJLG53MYZzF+L5fLoWnaWfA2r436G+SMjH6xN+kfnE4Qygm9cOwAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/cd22cee2bcfe9d94d47e596404574668/6d87c/Brain-MRI.png","srcSet":"/static/cd22cee2bcfe9d94d47e596404574668/39c10/Brain-MRI.png 175w,\n/static/cd22cee2bcfe9d94d47e596404574668/53f03/Brain-MRI.png 350w,\n/static/cd22cee2bcfe9d94d47e596404574668/6d87c/Brain-MRI.png 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/cd22cee2bcfe9d94d47e596404574668/78c08/Brain-MRI.avif 175w,\n/static/cd22cee2bcfe9d94d47e596404574668/64ae1/Brain-MRI.avif 350w,\n/static/cd22cee2bcfe9d94d47e596404574668/0b4bd/Brain-MRI.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/cd22cee2bcfe9d94d47e596404574668/04800/Brain-MRI.webp 175w,\n/static/cd22cee2bcfe9d94d47e596404574668/930ba/Brain-MRI.webp 350w,\n/static/cd22cee2bcfe9d94d47e596404574668/ddf38/Brain-MRI.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":388}}},"tech":["PyTorch","Deep Learning","Streamlit","Docker"],"github":"https://github.com/mishra-18/MRI-Segmentation","external":"https://huggingface.co/spaces/smishr-18/MRISegmentation/tree/main","cta":null},"html":"<p>Trained a UNet model for segmenting Tumours in MRI Brain scans. Achieved a <b>high validation Dice Score ~0.9</b>. Available with a docker image on DockerHub, and deployed on <a href=\"https://huggingface.co/spaces/smishr-18/MRISegmentation/tree/main\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Huggingface Space</a></p>"}},{"node":{"frontmatter":{"title":"Pool of ML-Models","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsSAAALEgHS3X78AAABpUlEQVQoz23QXY+aQBSAYf7/v2gvtkmbNNnY2nU31aytKGxXt+iCKCDDOCjDDB8OwwAq07jJNm3T5+LcnOTk5FXkX9q2lW0r/6tp6rqupZQ8xbu1wXOq/LmuORN58s+11yGT5BBHe5wWmj697/fhnipV5DFopmlOD4kbPLhuQFkja3Y8nnxs+b4NcCmlpJwa6882QOp829Od4cwxNolyQA6xHxKaesjrTd58HRn6YlP6Mxrjm8cPQ+3+k7qW2X5q9W/H776MV2MzvOrNPvYNzY6VND/gOM7SzENub/J2oM6nq11KIozJzY/3I33Y1dwy2mo/u3eT69uJO1qg7vfngfqkW6EihIhwRGKSsQygp40HaHESvGBFgRJ3Cx2Ai5e3yWa7RLhQn8PO4LH/TdcW4BLs+EJKWbK8yMjvTufzOUuT9rV+ycXp2JCcD9Vpp3Pnb7FyyV83VVWJqsqyjCSJqISoBGNMCHFgrOAX4qIsheCcUejsNyYvciUIgL2yTcsyTdNxHWtpLZfL9Xo1n889z4uifRiGAIBwhyCEAPgQBhChAMKYkF+Lw+iaqLtneQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/ab85aba4585ee0992c3eba215587bd4c/bf6b5/ViTs.png","srcSet":"/static/ab85aba4585ee0992c3eba215587bd4c/bd2b4/ViTs.png 175w,\n/static/ab85aba4585ee0992c3eba215587bd4c/70051/ViTs.png 350w,\n/static/ab85aba4585ee0992c3eba215587bd4c/bf6b5/ViTs.png 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/ab85aba4585ee0992c3eba215587bd4c/fa27b/ViTs.avif 175w,\n/static/ab85aba4585ee0992c3eba215587bd4c/327cd/ViTs.avif 350w,\n/static/ab85aba4585ee0992c3eba215587bd4c/d1e48/ViTs.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/ab85aba4585ee0992c3eba215587bd4c/db524/ViTs.webp 175w,\n/static/ab85aba4585ee0992c3eba215587bd4c/b4a32/ViTs.webp 350w,\n/static/ab85aba4585ee0992c3eba215587bd4c/994b4/ViTs.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":323}}},"tech":["Pytorch","ViTs"],"github":"https://github.com/mishra-18/ML-Models","external":"https://github.com/mishra-18/ML-Models","cta":null},"html":"<ul>\n<li>\n<p>A personal <a href=\"https://github.com/bchiang7/spotify-profile\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">GitHub repository</a> containing a variety of DL architectures implemented from scratch using PyTorch and einops for dealing with high-dimension tensors.</p>\n</li>\n<li>\n<p>The architecture mainly includes important Vision Transformers like Swin, Dino, MAE, CvT, etc.</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Generate Study Resources","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACrklEQVQoz0WTzW8TVxTFjUQ8k7Hn482MPyfjZJxxjBXHToCYkgAJKoQ0hRZCgiGfgISjFCUlEkSoSEgIJFgAEqVlwaKqKoSQWLFECMG2lRD/TPe/6j0oLM7q3XfuOefem0gmk+i6jq5JGKSMNK7r4ns+uVyOIAgUoihibGyMWq1Gf38/AwMD9PT0kM/nFXzfx3EcEpqmISF8i6AvQ9CbwfM8crk8xWKRMCwxODhIu91m68oVFhcWaDabxHGsmhQKBbLZrPpj2/ZnwqROVC9wcLZGazLGFT7FYoFSqaRIV1dX2L52jc2NDX7e3GRtbU01kUqlSulEEkpnCV3TSGo6lUqB/eMxfq+HJ1xVGARZyuUyMzM/srKyTKfTYX19nfm5eRqNBruqVaVS1mYymU8Ku7u72anrlIXPCTdL3XKI4gNMHvyVUu9ujhy+TmvPaY5Nfcv01DFlV+Y3e3qOoXqdKCoThqHKUapMGIaBmU5j2DaBZTBaHMD1hlmdPc752WlWl97ww4nHDLUmKVcrStnZcwuca8+zuCjzHCaXz3/JURFKWKaJ7QpSwuXo4Tke/VLn9tWHLC3/y8XFD9w/tc1MfZS4tovRkRGqw/sZaoxQqcQqZ5lfOp3+ZFkSplIpjO4uJsbPcOPOC5bPHOfvt+95+eQ5r36/zMfzF/jn8V+0Jg4wvm+C3pvP2Hd2gzgMcT0Py7IUR0LtoK6TNAz+aC/wW+cd97/fojM1zfbNBzy9d4m7t65TrY1QbzSIoz7yzUP03XlJ7uRlXOGqYThCKNKvhJrGN7Umfy79xOutq8x/N8PeVougp04mG2KaBqZpqhURuQJ7B5uEpQjLEQghlGX5npCX8v9yJ3Yk1HAM4bGjqwvbshDCwTTTOLajrkEGn/E8hOfhODbpVEplJ+1KYf8Blv5N1z4SZ0QAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/62464fe0cfa570596aa7ed7831c9571b/3f92b/AIL.png","srcSet":"/static/62464fe0cfa570596aa7ed7831c9571b/04107/AIL.png 119w,\n/static/62464fe0cfa570596aa7ed7831c9571b/a8b32/AIL.png 237w,\n/static/62464fe0cfa570596aa7ed7831c9571b/3f92b/AIL.png 474w","sizes":"(min-width: 474px) 474px, 100vw"},"sources":[{"srcSet":"/static/62464fe0cfa570596aa7ed7831c9571b/848d3/AIL.avif 119w,\n/static/62464fe0cfa570596aa7ed7831c9571b/dc774/AIL.avif 237w,\n/static/62464fe0cfa570596aa7ed7831c9571b/ba17c/AIL.avif 474w","type":"image/avif","sizes":"(min-width: 474px) 474px, 100vw"},{"srcSet":"/static/62464fe0cfa570596aa7ed7831c9571b/78056/AIL.webp 119w,\n/static/62464fe0cfa570596aa7ed7831c9571b/6b0c7/AIL.webp 237w,\n/static/62464fe0cfa570596aa7ed7831c9571b/0128d/AIL.webp 474w","type":"image/webp","sizes":"(min-width: 474px) 474px, 100vw"}]},"width":700,"height":378.0590717299578}}},"tech":["Pytorch","ViTs"],"github":"https://github.com/mishra-18/AI-Study-Material","external":"https://github.com/mishra-18/AI-Study-Material","cta":null},"html":"<ul>\n<li>\n<p>A Flask-based <a href=\"https://github.com/bchiang7/spotify-profile\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Web Application</a> that generates study resources from PDFs, employing LLMs to create content MCQs, Flash Cards, and Q&#x26;As.</p>\n</li>\n<li>\n<p>Assured content accuracy by implementing advanced and tight model prompting to prevent hallucinations.</p>\n</li>\n</ul>\n<p>Implemented front-end in HTML, CSS, and Vue.js.</p>"}},{"node":{"frontmatter":{"title":"LipReading With LipNet","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC4ElEQVQozz2Sa0iTYRTHX7apm7qri9A0srz0paALQaFQZh9SMIooZWXYpoa2TCMrs9RKbBBWZCD1ocgZ06azLIqiCySVOksmXuhLRBcstJpizjn9xftOOnA453k+/J/f/zxHUKvVaLVa9Ho9BoMBo3ER+/ftpbK8koJcK4fNJRSZj1NaUEpjfRltjhPcqC+jNN9CTlYmMTExaLUaRB2VSoUQGRmJTqeTMjommpPlR7l68RplhWc5dugMVvM5KosqeOaopPfFeTqbzlJ9pJjygyb2bNlOfHw8Go1GSklQVBbJFIoQ8g5kU11uY1V8BmnrdrJhdS6F2SZcj/JpeFfFg1eHKcnJZFfqdqx791B1JJOkpOXo9Qb0eh3h4eEIovIioxG5IoR8y37ydltRCStZEr6WxYo15KStp7MzA3ufmb6BnbxsS8WSkULXk1M8flhNbOxSya7o9L/lqKgo5PIQiovMVBRXsUK3kfXLtrItdQcXSrN48zybT5/zGPmYx42GLLqeltB5/zqbNqWi0+klQZFO1BLERvwUpVLFls0pXLbVUn3iJLaaGi7V27hysYY2Zx2Nt200NdVhqztNTe0xjIbFCIKATCaTakRERFAwLCxMasSanr6Njg4X7fc7aG2+w92b12lpcXDrTitNzfdouG3H4XTisN/F2eqgvb0dl8uFvbmZuLg4SUNQKpUSsviK1WpFjHm/jzH3c751PWCegHTnA6ZZiJkx5gH/wnHO5yMhIQG5XI4QGhoaHKYgYLFYmPb+or+lkW77Fb7+HGVy2s/3CS8/piaY+utl/OsIv358YXxyip9/JvB7vYyNjkrro1AogoQatRqZTE5hQT7fnrUy6LxGYG5GIpgBxgP+IGdgEt/Ub8ZnF9Bmg/T+wCzJycmIcII4THGpRf8mkwnPh1563r5maGgY9/v3vO3u4U13Nx6PB3dvDx/6++n3DDA4NEyf283wyAhut5vExETJ6T/gPAHeAEQtaQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/cfa766b1cf69ea3228cfc0c4963cc348/315a5/LIP.png","srcSet":"/static/cfa766b1cf69ea3228cfc0c4963cc348/d6b1f/LIP.png 153w,\n/static/cfa766b1cf69ea3228cfc0c4963cc348/fad5e/LIP.png 305w,\n/static/cfa766b1cf69ea3228cfc0c4963cc348/315a5/LIP.png 610w","sizes":"(min-width: 610px) 610px, 100vw"},"sources":[{"srcSet":"/static/cfa766b1cf69ea3228cfc0c4963cc348/d7fb2/LIP.avif 153w,\n/static/cfa766b1cf69ea3228cfc0c4963cc348/c5ec9/LIP.avif 305w,\n/static/cfa766b1cf69ea3228cfc0c4963cc348/0c739/LIP.avif 610w","type":"image/avif","sizes":"(min-width: 610px) 610px, 100vw"},{"srcSet":"/static/cfa766b1cf69ea3228cfc0c4963cc348/7a922/LIP.webp 153w,\n/static/cfa766b1cf69ea3228cfc0c4963cc348/f2740/LIP.webp 305w,\n/static/cfa766b1cf69ea3228cfc0c4963cc348/14c4c/LIP.webp 610w","type":"image/webp","sizes":"(min-width: 610px) 610px, 100vw"}]},"width":700,"height":400.4918032786885}}},"tech":["Pytorch","Opencv"],"github":"https://github.com/mishra-18/lipnet-pytorch","external":"https://github.com/mishra-18/lipnet-pytorch","cta":""},"html":"<ul>\n<li>\n<p>Developed a <b>3DConv-LSTM</b> (bi-directional) to predict the spoken sentence by extracting features from the lip movements in the frames based on <a href=\"https://github.com/mishra-18/lipnet-pytorch\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">End-to-End Sentence-level Lipreading</a>.</p>\n</li>\n<li>\n<p>Utilized CTC Loss for training to handle the variable length of input alignments (spoken sentence) and weights initialized with <b>He</b> (Kaiming normal) initialization to avoid blank-index predictions.</p>\n</li>\n</ul>"}}]}}}