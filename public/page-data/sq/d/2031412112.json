{"data":{"featured":{"edges":[{"node":{"frontmatter":{"title":"Segmentation for Tumor Detection","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABx0lEQVQoz22SS2/aYBBFbUN52GAnPGrAKsIkvEILwXwGDHZC7QCbrqIu+lJaqauq2676508FyCkEFrMYzeho5t4rSZJEXKVSiWq1SqFQwDTNXcmyzOFOXEb+glKhjKpqL2f/G0VRUBLKMySRSJyFtewWbiSYhiMmrkOn0yGVSp0CY0i/38eyrLOw7Ksso+WQ7B8Dy/fp+T7TucB8bZ4CC2UdMRyxCldsNhu63S7pdPoImElmcVYDzI997Np38j9nlIWOJClI8gEwLedpzX2aT7dEH5as1muCINi9s5Xi6OWrNg/Rey6bl2S9DGpJRZbk4wsriRpfpAGW80jra4+JcJlOp7iui2EYR8BkMomu68+9pmpkspm435PVRMSjtOYm9xc3XODNZiwWPvP5fOf6Sy2LxSLtTht3OKFeqR/O9sCiauPZn8n/GCP8IWLk4nneDhjrGLu/jVcURYT3If2nHs4nh4pZPjVlIG7p/m7yNnpHeBcSPUQ0Go2T665b14ThFhhQ/tXlavSNmrE8BaaTKW46fYbOkLEzxrbts9Gp1+sIIVje3zH2A0QxwJLG53MYZzF+L5fLoWnaWfA2r436G+SMjH6xN+kfnE4Qygm9cOwAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/cd22cee2bcfe9d94d47e596404574668/6d87c/Brain-MRI.png","srcSet":"/static/cd22cee2bcfe9d94d47e596404574668/39c10/Brain-MRI.png 175w,\n/static/cd22cee2bcfe9d94d47e596404574668/53f03/Brain-MRI.png 350w,\n/static/cd22cee2bcfe9d94d47e596404574668/6d87c/Brain-MRI.png 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/cd22cee2bcfe9d94d47e596404574668/78c08/Brain-MRI.avif 175w,\n/static/cd22cee2bcfe9d94d47e596404574668/64ae1/Brain-MRI.avif 350w,\n/static/cd22cee2bcfe9d94d47e596404574668/0b4bd/Brain-MRI.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/cd22cee2bcfe9d94d47e596404574668/04800/Brain-MRI.webp 175w,\n/static/cd22cee2bcfe9d94d47e596404574668/930ba/Brain-MRI.webp 350w,\n/static/cd22cee2bcfe9d94d47e596404574668/ddf38/Brain-MRI.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":388}}},"tech":["PyTorch","Deep Learning","Streamlit","Docker"],"github":"https://github.com/bchiang7/halcyon-site","external":"https://halcyon-theme.netlify.com/","cta":null},"html":"<p>Used a UNet model for segmenting Tumours in MRI Brain scans. Trained from scratch and achieved a high validation Dice Score ~0.9. Available with a docker <a href=\"https://marketplace.visualstudio.com/items?itemName=brittanychiang.halcyon-vscode\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">image</a> on DockerHub, and deployed on <a href=\"https://packagecontrol.io/packages/Halcyon%20Theme\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Huggingface Space</a></p>"}},{"node":{"frontmatter":{"title":"Pool of ML-Models","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsSAAALEgHS3X78AAABpUlEQVQoz23QXY+aQBSAYf7/v2gvtkmbNNnY2nU31aytKGxXt+iCKCDDOCjDDB8OwwAq07jJNm3T5+LcnOTk5FXkX9q2lW0r/6tp6rqupZQ8xbu1wXOq/LmuORN58s+11yGT5BBHe5wWmj697/fhnipV5DFopmlOD4kbPLhuQFkja3Y8nnxs+b4NcCmlpJwa6882QOp829Od4cwxNolyQA6xHxKaesjrTd58HRn6YlP6Mxrjm8cPQ+3+k7qW2X5q9W/H776MV2MzvOrNPvYNzY6VND/gOM7SzENub/J2oM6nq11KIozJzY/3I33Y1dwy2mo/u3eT69uJO1qg7vfngfqkW6EihIhwRGKSsQygp40HaHESvGBFgRJ3Cx2Ai5e3yWa7RLhQn8PO4LH/TdcW4BLs+EJKWbK8yMjvTufzOUuT9rV+ycXp2JCcD9Vpp3Pnb7FyyV83VVWJqsqyjCSJqISoBGNMCHFgrOAX4qIsheCcUejsNyYvciUIgL2yTcsyTdNxHWtpLZfL9Xo1n889z4uifRiGAIBwhyCEAPgQBhChAMKYkF+Lw+iaqLtneQAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/ab85aba4585ee0992c3eba215587bd4c/bf6b5/ViTs.png","srcSet":"/static/ab85aba4585ee0992c3eba215587bd4c/bd2b4/ViTs.png 175w,\n/static/ab85aba4585ee0992c3eba215587bd4c/70051/ViTs.png 350w,\n/static/ab85aba4585ee0992c3eba215587bd4c/bf6b5/ViTs.png 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/ab85aba4585ee0992c3eba215587bd4c/fa27b/ViTs.avif 175w,\n/static/ab85aba4585ee0992c3eba215587bd4c/327cd/ViTs.avif 350w,\n/static/ab85aba4585ee0992c3eba215587bd4c/d1e48/ViTs.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/ab85aba4585ee0992c3eba215587bd4c/db524/ViTs.webp 175w,\n/static/ab85aba4585ee0992c3eba215587bd4c/b4a32/ViTs.webp 350w,\n/static/ab85aba4585ee0992c3eba215587bd4c/994b4/ViTs.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":323}}},"tech":["Pytorch","ViTs"],"github":"https://github.com/bchiang7/spotify-profile","external":"https://spotify-profile.herokuapp.com/","cta":null},"html":"<ul>\n<li>\n<p>A personal GitHub repository containing a variety of DL architectures implemented from scratch using PyTorch and einops for dealing with higher dimension tensor.</p>\n</li>\n<li>\n<p>The architecture mainly includes important Vision Tramsformers like Swinn, Dino, MAE, CvT, etc.</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Generate Study Resources","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABiklEQVQoz42STUsbURhG/ZNCt6LQiuLCtoIzZibRlIKQuAiVkIX4CcGKWCFKP6BiSqKJk2S8d5L4mY1uXASDNiqSOWWu0zKSFrp44PLe4XCeO2+PicRAYLoCHYnuHmI82uhq5t1JDFeohHEIU1Ux/bkZuPfOPergCiaQxK7LfD21KTTqJG+kD3360IMN1TYZFBsqY80cEep/QL+jgGFXMo4g3bC4lEc0SpIvoqBsPRvtZ5FX5TUGimn6fizRn1/hZXmNkfPPmDjPDRXZG3gWjzaplmTZ+k7ieJeQqucQeqig3RbR2gfo9yX0toV+Z6G1rb9XNgJQz9To2AzvFHhTFPTFV9Cqe0Q5x3ClMgqmq3LQ0OwIIji8bdlE7QzpbIoXvRajMwdMX+XUO5u+TdCqu3IAGnErTJ04JEWF7UKGhXiGregk2dWPvOeMUMdWfz9o1W3oAzWqzDbzrL+e51NsjsXWMasX3/hwW+IddSZdf1X+Dyj99amSaO6TvPLerYbWOVL7GSJQEfFP4C8Anko4zSSnLAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/01ac9bb3ba7cb773ad74e1eb92f50263/94985/AI.png","srcSet":"/static/01ac9bb3ba7cb773ad74e1eb92f50263/64325/AI.png 112w,\n/static/01ac9bb3ba7cb773ad74e1eb92f50263/3235f/AI.png 224w,\n/static/01ac9bb3ba7cb773ad74e1eb92f50263/94985/AI.png 448w","sizes":"(min-width: 448px) 448px, 100vw"},"sources":[{"srcSet":"/static/01ac9bb3ba7cb773ad74e1eb92f50263/5e294/AI.avif 112w,\n/static/01ac9bb3ba7cb773ad74e1eb92f50263/c9e8e/AI.avif 224w,\n/static/01ac9bb3ba7cb773ad74e1eb92f50263/56105/AI.avif 448w","type":"image/avif","sizes":"(min-width: 448px) 448px, 100vw"},{"srcSet":"/static/01ac9bb3ba7cb773ad74e1eb92f50263/48e53/AI.webp 112w,\n/static/01ac9bb3ba7cb773ad74e1eb92f50263/f3046/AI.webp 224w,\n/static/01ac9bb3ba7cb773ad74e1eb92f50263/0b7b6/AI.webp 448w","type":"image/webp","sizes":"(min-width: 448px) 448px, 100vw"}]},"width":700,"height":326.5625}}},"tech":["Pytorch","ViTs"],"github":"https://github.com/bchiang7/spotify-profile","external":"https://spotify-profile.herokuapp.com/","cta":null},"html":"<ul>\n<li>\n<p>A Flask-based web application that generates study resources from PDFs, employing LLMs to create content MCQs, Flash Cards, and Q&#x26;As.</p>\n</li>\n<li>\n<p>Assured content accuracy by implementing advance and tight model prompting to prevent hallucinations.</p>\n</li>\n</ul>\n<p>Implemented front-end in HTML, CSS, and VueJS.</p>"}},{"node":{"frontmatter":{"title":"LipReading With LipNet","cover":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACXUlEQVQozzXQSUjUARjG4e+fZnYwiA5q5oyIjY5rdEqQckszy6KD5S3qooIVBUkRURoaRuS4YTiKe01qqAmaoWVulam4mzrCGCpJIBQuzTj+YsY6vJf38PB9r4gEIcpRRPztcZEwPCUOlZzloMRzL62U+upu8rMbKch5Q35mC036Mnp78nnXXETlsxrupuhQJByRMGQHCkbEz579EoFaTuMlCeRlGqgobCcnvZbHdwzoHlTTYHhC61g279sfUp6ho+qRjszkHBwdIxA7aocCEPFFES0HlChUEo+/00VePG8nxvc2keobHHe7RXJkIoaPIaR9uUBLv5aC66FkJaXSVpeB894oRE7YQBsWiIg3DuKPq0SjkjgCnJJ4WfyWcwHpxHpcI16bSsbleDpa/eg3aRgxelH29BjGwZuUlRUjEsEuxX6hdmc/RY2DBOImMXZQK4mUZDdSlNVA7v068nMbKcmrpKm1kMomPRUGPfryWkprDOxzSUIkFJGT/1/2RRQVuyUYV4lFrZxBI4nU6ztZWv7FSN8oX1s/MDqyxMDnFbp6TQwOrTA+vEBnxwzdvZP09Ezg7X3FBvog4oXIIfZICK4SibeSwGFJZHhgHtZXmG4u5fvUJ6zAOmY2sLC9tcr22hLr9hawmAkOSrWBakRUiHjibAOVcHwkAR/lEm1Vjcy91mEa6mLThlmt/DCvg3WN3z9NrG5s8sdigc0NtswWAgNTbKA7Ih7/wCO4K9Fo5DxucorK4ldM9PdhNC4yObnA0PAcY1MmpifmGR83MTm7wsy3ReZmF5mdW0ajucpfv76e5gAGQEwAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/bd2baf6210a3b41d59708b7c5acf41a6/0051a/Test2.png","srcSet":"/static/bd2baf6210a3b41d59708b7c5acf41a6/52ed0/Test2.png 175w,\n/static/bd2baf6210a3b41d59708b7c5acf41a6/8a9b3/Test2.png 350w,\n/static/bd2baf6210a3b41d59708b7c5acf41a6/0051a/Test2.png 700w","sizes":"(min-width: 700px) 700px, 100vw"},"sources":[{"srcSet":"/static/bd2baf6210a3b41d59708b7c5acf41a6/30dfb/Test2.avif 175w,\n/static/bd2baf6210a3b41d59708b7c5acf41a6/c822d/Test2.avif 350w,\n/static/bd2baf6210a3b41d59708b7c5acf41a6/5624b/Test2.avif 700w","type":"image/avif","sizes":"(min-width: 700px) 700px, 100vw"},{"srcSet":"/static/bd2baf6210a3b41d59708b7c5acf41a6/21ab0/Test2.webp 175w,\n/static/bd2baf6210a3b41d59708b7c5acf41a6/c9690/Test2.webp 350w,\n/static/bd2baf6210a3b41d59708b7c5acf41a6/86a7f/Test2.webp 700w","type":"image/webp","sizes":"(min-width: 700px) 700px, 100vw"}]},"width":700,"height":326}}},"tech":["React","Express","Spotify API","Styled Components"],"github":null,"external":"https://www.newline.co/courses/build-a-spotify-connected-app","cta":"https://www.newline.co/courses/build-a-spotify-connected-app"},"html":"<ul>\n<li>\n<p>Developed a 3DConv-LSTM (bi-directional) to predict the spoken sentence by extracting features from the lip movements in the frames based on End-to-End Sentence-level Lipreading.</p>\n</li>\n<li>\n<p>Utilized CTC Loss for training to handle the variable length of input alignments (spoken sentence) and weights initialized with He (Kaiming normal) initialization to avoid blank-index predictions.</p>\n</li>\n</ul>"}}]}}}